{
  "hash": "74148177e014eb5410466f9e251a05b2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"logic_reg\"\nauthor: \"강남규\"\ndate: \"2024-09-010\"\ncategories: [bigdata]\n---\n\n\n**로지스틱 회귀분석 이해하기**\n\n# 패키지 불러오기\n\n::: {#a47d235e .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\nimport statsmodels.api as sm\n```\n:::\n\n\n# Q1\n**데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.**\n\n::: {#17cf12f0 .cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/shinydashboard/data/leukemia_remission.csv')\nmodel = sm.formula.logit(\"REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP\",\n                         data=df).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 10 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        13:06:07   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified.\n```\n:::\n:::\n\n\n# Q2\n\n**해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.**\n\n유의수준 0.05하에서 LLR p-value가 0.0467로\n유의수준보다 작으므로 통계적으로 유의하다.\n\n# Q3\n\n**유의수준 0.2를 기준으로 통계적으로 유의한 변수**\n\n P>|z|가 0.2보다 작은 변수는 **LI**, **TEMP**\n\n# Q4\n\n**다음 환자에 대한 오즈는 얼마인가요?**\n\nCELL (골수의 세포성): 65%<br>\nSMEAR (골수편의 백혈구 비율): 45%<br>\nINFIL (골수의 백혈병 세포 침투 비율): 55%<br>\nLI (골수 백혈병 세포의 라벨링 인덱스): 1.2<br>\nBLAST (말초혈액의 백혈병 세포 수): 1.1 세포/μL<br>\nTEMP (치료 시작 전 최고 체온): 0.9<br>\n\n::: {#5220c23b .cell execution_count=3}\n``` {.python .cell-code}\ncoefficients = model.params\nmy_odds = np.exp(64.2581 +30.8301*0.65 + 24.6863*0.45 -24.9745*0.55 +4.3605*1.2 -0.0115*1.1 -100.1734*0.9)\nprint(my_odds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.03817459641135519\n```\n:::\n:::\n\n\n# Q5\n\n**위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?**\n\n::: {#1d006294 .cell execution_count=4}\n``` {.python .cell-code}\nround(my_odds / (my_odds+1),3)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nnp.float64(0.037)\n```\n:::\n:::\n\n\n# Q6\n\n**TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.**\n\n계수는 -100.1734\n\n::: {#e5d4072d .cell execution_count=5}\n``` {.python .cell-code}\nodd_ratio = np.exp(-100.1734)\nprint(odd_ratio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.1278444454718357e-44\n```\n:::\n:::\n\n\n온도가 1단위 증가해도 백혈병 비관측에 대한 오즈가 증가하지 않는다.\n\n# Q7\n\n**CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.**\n\n::: {#79bc5d60 .cell execution_count=6}\n``` {.python .cell-code}\ncell_coef = model.params['CELL']\ncell_se = model.bse['CELL']\nz = norm.ppf(0.995)\nlower_bound_coef = cell_coef - z * cell_se\nupper_bound_coef = cell_coef + z* cell_se\nlower_bound_or = np.exp(lower_bound_coef)\nupper_bound_or = np.exp(upper_bound_coef)\nprint(f\"오즈비의 신뢰구간은{lower_bound_or}에서 {upper_bound_or}까지지\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n오즈비의 신뢰구간은1.1673039739716536e-45에서 5.145962460342642e+71까지지\n```\n:::\n:::\n\n\n# Q8\n\n**주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후,**<br>\n**50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.**\n\n::: {#b3bcd7cd .cell execution_count=7}\n``` {.python .cell-code}\ndf['predicted'] = model.predict() >= 0.5\nfrom sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(df['REMISS'], df['predicted'])\nprint(conf_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[15  3]\n [ 4  5]]\n```\n:::\n:::\n\n\n# Q9\n\n**해당 모델의 Accuracy는 얼마인가요?**\n\n::: {#5b017986 .cell execution_count=8}\n``` {.python .cell-code}\naccuracy = accuracy_score(df['REMISS'], df['predicted'])\nprint(f'accuracy점수는 {accuracy}입니다.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\naccuracy점수는 0.7407407407407407입니다.\n```\n:::\n:::\n\n\n# Q10\n\n**해당 모델의 F1 Score를 구하세요.*\n\n::: {#48294a2d .cell execution_count=9}\n``` {.python .cell-code}\nf1 = f1_score(df['REMISS'], df['predicted'])\nprint(f'f1점수는 {f1}입니다.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nf1점수는 0.5882352941176471입니다.\n```\n:::\n:::\n\n\n",
    "supporting": [
      "logic_reg_files"
    ],
    "filters": [],
    "includes": {}
  }
}